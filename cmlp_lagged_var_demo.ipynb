{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cMLP Lagged VAR Demo\n",
    "- In this notebook, we train a cMLP model on data simulated from a vector autoregressive (VAR) process with lagged interactions. We use the hierarchical sparse penalty to perform lag selection.\n",
    "- We use unregularized pretraining before training with GISTA.\n",
    "- After examining the Granger causality discovery, we train a debiased model using only the discovered interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from models.cmlp import cMLP, cMLPSparse, train_model_adam, train_model_gista\n",
    "from synthetic import simulate_var\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For GPU acceleration\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate data\n",
    "p = 10\n",
    "T = 1000\n",
    "var_lag = 3\n",
    "X_np, beta, GC = simulate_var(p, T, var_lag)\n",
    "X = torch.tensor(X_np[np.newaxis], dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
    "axarr[0].plot(X_np)\n",
    "axarr[1].plot(X_np[:100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model\n",
    "lag = 5\n",
    "hidden = [10]\n",
    "cmlp = cMLP(p, lag, hidden).cuda(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrain (no regularization)\n",
    "check_every = 1000\n",
    "train_loss_list = train_model_adam(cmlp, X, lr=1e-2, niter=10000, check_every=check_every)\n",
    "\n",
    "# Plot loss function\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Pretraining')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Iterations')\n",
    "plt.plot(check_every * np.arange(len(train_loss_list)), train_loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with GISTA\n",
    "check_every = 1000\n",
    "train_loss_list, train_mse_list = train_model_gista(\n",
    "    cmlp, X, lam=0.011, lam_ridge=1e-4, lr=0.02, penalty='H', max_iter=50000, check_every=check_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function plot\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "axarr[0].plot(check_every * np.arange(len(train_loss_list)), train_loss_list)\n",
    "axarr[0].set_title('Train loss')\n",
    "\n",
    "axarr[1].plot(check_every * np.arange(len(train_mse_list)), train_mse_list)\n",
    "axarr[1].set_title('Train MSE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify learned Granger causality\n",
    "GC_est = cmlp.GC().cpu().data.numpy()\n",
    "\n",
    "print('True variable usage = %.2f%%' % (100 * np.mean(GC)))\n",
    "print('Estimated variable usage = %.2f%%' % (100 * np.mean(GC_est)))\n",
    "print('Accuracy = %.2f%%' % (100 * np.mean(GC == GC_est)))\n",
    "\n",
    "# Make figures\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
    "axarr[0].imshow(GC, cmap='Blues')\n",
    "axarr[0].set_title('GC actual')\n",
    "axarr[0].set_ylabel('Affected series')\n",
    "axarr[0].set_xlabel('Causal series')\n",
    "axarr[0].set_xticks([])\n",
    "axarr[0].set_yticks([])\n",
    "\n",
    "axarr[1].imshow(GC_est, cmap='Blues', vmin=0, vmax=1, extent=(0, p, p, 0))\n",
    "axarr[1].set_title('GC estimated')\n",
    "axarr[1].set_ylabel('Affected series')\n",
    "axarr[1].set_xlabel('Causal series')\n",
    "axarr[1].set_xticks([])\n",
    "axarr[1].set_yticks([])\n",
    "\n",
    "# Mark disagreements\n",
    "for i in range(p):\n",
    "    for j in range(p):\n",
    "        if GC[i, j] != GC_est[i, j]:\n",
    "            rect = plt.Rectangle((j, i-0.05), 1, 1, facecolor='none', edgecolor='red', linewidth=1)\n",
    "            axarr[1].add_patch(rect)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify lag selection\n",
    "for i in range(p):\n",
    "    # Get true GC\n",
    "    GC_lag = np.zeros((lag, p))\n",
    "    GC_lag[:var_lag, GC[i].astype(bool)] = 1.0\n",
    "\n",
    "    # Get estimated GC\n",
    "    GC_est_lag = cmlp.GC(ignore_lag=False, threshold=False)[i].cpu().data.numpy().T[::-1]\n",
    "\n",
    "    # Make figures\n",
    "    fig, axarr = plt.subplots(1, 2, figsize=(16, 5))\n",
    "    axarr[0].imshow(GC_lag, cmap='Blues', extent=(0, p, lag, 0))\n",
    "    axarr[0].set_title('Series %d true GC' % (i + 1))\n",
    "    axarr[0].set_ylabel('Lag')\n",
    "    axarr[0].set_xlabel('Series')\n",
    "    axarr[0].set_xticks(np.arange(p) + 0.5)\n",
    "    axarr[0].set_xticklabels(range(p))\n",
    "    axarr[0].set_yticks(np.arange(lag) + 0.5)\n",
    "    axarr[0].set_yticklabels(range(1, lag + 1))\n",
    "    axarr[0].tick_params(axis='both', length=0)\n",
    "\n",
    "    axarr[1].imshow(GC_est_lag, cmap='Blues', extent=(0, p, lag, 0))\n",
    "    axarr[1].set_title('Series %d estimated GC' % (i + 1))\n",
    "    axarr[1].set_ylabel('Lag')\n",
    "    axarr[1].set_xlabel('Series')\n",
    "    axarr[1].set_xticks(np.arange(p) + 0.5)\n",
    "    axarr[1].set_xticklabels(range(p))\n",
    "    axarr[1].set_yticks(np.arange(lag) + 0.5)\n",
    "    axarr[1].set_yticklabels(range(1, lag + 1))\n",
    "    axarr[1].tick_params(axis='both', length=0)\n",
    "\n",
    "    # Mark nonzeros\n",
    "    for i in range(p):\n",
    "        for j in range(lag):\n",
    "            if GC_est_lag[j, i] > 0.0:\n",
    "                rect = plt.Rectangle((i, j), 1, 1, facecolor='none', edgecolor='green', linewidth=1.0)\n",
    "                axarr[1].add_patch(rect)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a debiased model\n",
    "sparsity = cmlp.GC().byte()\n",
    "cmlp_sparse = cMLPSparse(p, sparsity, lag, hidden).cuda(device=device)\n",
    "\n",
    "# Train\n",
    "check_every = 1000\n",
    "train_loss_list = train_model_adam(cmlp_sparse, X, lr=1e-3, niter=20000, check_every=check_every, verbose=1)\n",
    "\n",
    "# Plot loss function\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Debiased model training')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Iterations')\n",
    "plt.plot(check_every * np.arange(len(train_loss_list)), train_loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimal forecasts using VAR parameters\n",
    "X_optimal_forecast = np.zeros((p, T-var_lag))\n",
    "for t in range(T-var_lag):\n",
    "    X_optimal_forecast[:, t] = np.dot(beta, X_np.T[:, t:(t+var_lag)].flatten(order='F'))\n",
    "X_optimal_forecast = X_optimal_forecast.T\n",
    "\n",
    "# Forecast using debiased cMLP\n",
    "X_pred = cmlp_sparse(X)\n",
    "\n",
    "# Plot actual data and forecasts\n",
    "num_points = 10\n",
    "\n",
    "for i in range(p):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(X[0, var_lag:num_points+var_lag, i].cpu().data.numpy(), label='Actual')\n",
    "    plt.plot(X_pred[0, :num_points, i].cpu().data.numpy(), label='cMLP forecasting')\n",
    "    plt.plot(X_optimal_forecast[:num_points, i], label='Optimal forecasting')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Series %d forecasting' % (i + 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
